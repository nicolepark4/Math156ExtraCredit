{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c77a97a",
   "metadata": {},
   "source": [
    "## Math 156 Extra Credit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483fb21",
   "metadata": {},
   "source": [
    "### Sentiment Analysis, Hyperparameter Optimization, and Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eddd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "import math\n",
    "from nrclex import NRCLex \n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from itertools import chain\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import loguniform\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a89a78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5ae00",
   "metadata": {},
   "source": [
    "Goal: predict the number of stars in the review from the data.\\\n",
    "We will be using sentiment analysis to see whether we can predict the number of stars from the text review.\n",
    "Dataset can be downloaded from: https://www.kaggle.com/datasets/whenamancodes/amazon-reviews-on-women-dresses?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4f751e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s.no</th>\n",
       "      <th>age</th>\n",
       "      <th>division_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>alike_feedback_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>1028</td>\n",
       "      <td>Amazing fit and wash</td>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>850</td>\n",
       "      <td>Lovely and unique!</td>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>993</td>\n",
       "      <td>Meh</td>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1068</td>\n",
       "      <td>Wow</td>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Swim</td>\n",
       "      <td>24</td>\n",
       "      <td>Great for bigger busts</td>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s.no  age   division_name department_name class_name  clothing_id  \\\n",
       "0     0   40         General         Bottoms      Jeans         1028   \n",
       "1     1   62  General Petite            Tops    Blouses          850   \n",
       "2     2   47  General Petite         Bottoms     Skirts          993   \n",
       "3     3   45  General Petite         Bottoms      Pants         1068   \n",
       "4     4   37       Initmates        Intimate       Swim           24   \n",
       "\n",
       "                    title                                        review_text  \\\n",
       "0    Amazing fit and wash  Like other reviewers i was hesitant to spend t...   \n",
       "1      Lovely and unique!  As is true of a bunch of the fall clothing pho...   \n",
       "2                     Meh  I so wanted this skirt to work, love the desig...   \n",
       "3                     Wow  Love love this! i was hesitant to buy this at ...   \n",
       "4  Great for bigger busts  I absolutely love the retro look of this swims...   \n",
       "\n",
       "   alike_feedback_count  rating  recommend_index   \n",
       "0                     0       5                 1  \n",
       "1                    12       5                 1  \n",
       "2                     3       1                 0  \n",
       "3                     0       5                 1  \n",
       "4                     0       5                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing\n",
    "# ratings_Books.csv can be found in the GitHub\n",
    "ratings = pd.read_csv(\"WomensDressReviews.csv\", delimiter=',', header = 0)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad0b53",
   "metadata": {},
   "source": [
    "For simplicity, we can reduce the dataset to the review text and the rating, the two relevant features of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7653eaa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating\n",
       "0  Like other reviewers i was hesitant to spend t...       5\n",
       "1  As is true of a bunch of the fall clothing pho...       5\n",
       "2  I so wanted this skirt to work, love the desig...       1\n",
       "3  Love love this! i was hesitant to buy this at ...       5\n",
       "4  I absolutely love the retro look of this swims...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings[['review_text', 'rating']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fda59c",
   "metadata": {},
   "source": [
    "We will now clean our reviews by reducing them down to the key words that convey the sentiment of the user. First, we remove puncutation and reduce the review down to its core words. We do this using the $re.sub$ package that uses regular expression operations to remove puncutation and leave just the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93343636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(review):\n",
    "    review = re.sub('[^A-Za-z]+', ' ', str(review))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e86c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['Cleaned Reviews'] = ratings['review_text'].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94bd36d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>I so wanted this skirt to work love the design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Love love this i was hesitant to buy this at f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  \\\n",
       "0  Like other reviewers i was hesitant to spend t...       5   \n",
       "1  As is true of a bunch of the fall clothing pho...       5   \n",
       "2  I so wanted this skirt to work, love the desig...       1   \n",
       "3  Love love this! i was hesitant to buy this at ...       5   \n",
       "4  I absolutely love the retro look of this swims...       5   \n",
       "\n",
       "                                     Cleaned Reviews  \n",
       "0  Like other reviewers i was hesitant to spend t...  \n",
       "1  As is true of a bunch of the fall clothing pho...  \n",
       "2  I so wanted this skirt to work love the design...  \n",
       "3  Love love this i was hesitant to buy this at f...  \n",
       "4  I absolutely love the retro look of this swims...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f85cff",
   "metadata": {},
   "source": [
    "Now we will tokenize our data by breaking it down into categories. Since we are trying to extract sentiments from the reviews, we will be doing work tokeniation using the function $\\textit{word_tokenize}$ from the $\\textit{nltk tokenize}$ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9721e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_review = []\n",
    "for i in range(len(ratings['Cleaned Reviews'])):\n",
    "     tokenized_review.append(word_tokenize(ratings['Cleaned Reviews'][i]))\n",
    "# for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7398927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>tokenized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>[Like, other, reviewers, i, was, hesitant, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>[As, is, true, of, a, bunch, of, the, fall, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>I so wanted this skirt to work love the design...</td>\n",
       "      <td>[I, so, wanted, this, skirt, to, work, love, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Love love this i was hesitant to buy this at f...</td>\n",
       "      <td>[Love, love, this, i, was, hesitant, to, buy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>[I, absolutely, love, the, retro, look, of, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  \\\n",
       "0  Like other reviewers i was hesitant to spend t...       5   \n",
       "1  As is true of a bunch of the fall clothing pho...       5   \n",
       "2  I so wanted this skirt to work, love the desig...       1   \n",
       "3  Love love this! i was hesitant to buy this at ...       5   \n",
       "4  I absolutely love the retro look of this swims...       5   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  Like other reviewers i was hesitant to spend t...   \n",
       "1  As is true of a bunch of the fall clothing pho...   \n",
       "2  I so wanted this skirt to work love the design...   \n",
       "3  Love love this i was hesitant to buy this at f...   \n",
       "4  I absolutely love the retro look of this swims...   \n",
       "\n",
       "                                    tokenized_review  \n",
       "0  [Like, other, reviewers, i, was, hesitant, to,...  \n",
       "1  [As, is, true, of, a, bunch, of, the, fall, cl...  \n",
       "2  [I, so, wanted, this, skirt, to, work, love, t...  \n",
       "3  [Love, love, this, i, was, hesitant, to, buy, ...  \n",
       "4  [I, absolutely, love, the, retro, look, of, th...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['tokenized_review'] = tokenized_review\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7d550",
   "metadata": {},
   "source": [
    "Now we find the top emotions from each review based on the sentiment analysis from the word tokenization we did for each review. Based on these top emotions, we can create numerical training data for our model and then optimize our hyperparameters to increase model accuracy as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77191c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings['tokenized_review'] = tokenized_review\n",
    "clean = ratings['Cleaned Reviews']\n",
    "emotion = [0]*len(clean)\n",
    "for i in range(len(clean)):\n",
    "        emotion[i] = NRCLex(clean[i]).top_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a084da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>[Like, other, reviewers, i, was, hesitant, to,...</td>\n",
       "      <td>[(positive, 0.3333333333333333)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>[As, is, true, of, a, bunch, of, the, fall, cl...</td>\n",
       "      <td>[(positive, 0.3448275862068966)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>I so wanted this skirt to work love the design...</td>\n",
       "      <td>[I, so, wanted, this, skirt, to, work, love, t...</td>\n",
       "      <td>[(positive, 0.25), (negative, 0.25), (joy, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Love love this i was hesitant to buy this at f...</td>\n",
       "      <td>[Love, love, this, i, was, hesitant, to, buy, ...</td>\n",
       "      <td>[(positive, 0.19047619047619047), (joy, 0.1904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>[I, absolutely, love, the, retro, look, of, th...</td>\n",
       "      <td>[(positive, 0.2222222222222222)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  \\\n",
       "0  Like other reviewers i was hesitant to spend t...       5   \n",
       "1  As is true of a bunch of the fall clothing pho...       5   \n",
       "2  I so wanted this skirt to work, love the desig...       1   \n",
       "3  Love love this! i was hesitant to buy this at ...       5   \n",
       "4  I absolutely love the retro look of this swims...       5   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  Like other reviewers i was hesitant to spend t...   \n",
       "1  As is true of a bunch of the fall clothing pho...   \n",
       "2  I so wanted this skirt to work love the design...   \n",
       "3  Love love this i was hesitant to buy this at f...   \n",
       "4  I absolutely love the retro look of this swims...   \n",
       "\n",
       "                                    tokenized_review  \\\n",
       "0  [Like, other, reviewers, i, was, hesitant, to,...   \n",
       "1  [As, is, true, of, a, bunch, of, the, fall, cl...   \n",
       "2  [I, so, wanted, this, skirt, to, work, love, t...   \n",
       "3  [Love, love, this, i, was, hesitant, to, buy, ...   \n",
       "4  [I, absolutely, love, the, retro, look, of, th...   \n",
       "\n",
       "                                             emotion  \n",
       "0                   [(positive, 0.3333333333333333)]  \n",
       "1                   [(positive, 0.3448275862068966)]  \n",
       "2  [(positive, 0.25), (negative, 0.25), (joy, 0.2...  \n",
       "3  [(positive, 0.19047619047619047), (joy, 0.1904...  \n",
       "4                   [(positive, 0.2222222222222222)]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['emotion'] = emotion\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0935",
   "metadata": {},
   "source": [
    "For each review, we add the top emotion and the probability of the emotion occurring in the review based on our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "407d1657",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos = 0\n",
    "core = []\n",
    "prob = []\n",
    "for i in range(ratings.shape[0]):\n",
    "        if((ratings['emotion'][i][0][0]) == 'positive'): \n",
    "            core.append('positive')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'negative'):\n",
    "            core.append('negative')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'joy'):\n",
    "            core.append('joy')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'trust'):\n",
    "            core.append('trust')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'fear'):\n",
    "            core.append('fear')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'anger'):\n",
    "            core.append('anger')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'sadness'):\n",
    "            core.append('sadness')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'disgust'):\n",
    "            core.append('disgust')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        elif(ratings['emotion'][i][0][0] == 'surprise'):\n",
    "            core.append('surprise')\n",
    "            prob.append(ratings['emotion'][i][0][1])\n",
    "        else:\n",
    "            core.append(0)\n",
    "            prob.append(ratings['emotion'][i][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f06faf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings['core'] = core\n",
    "ratings['prob'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826ed808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>emotion</th>\n",
       "      <th>core</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>[Like, other, reviewers, i, was, hesitant, to,...</td>\n",
       "      <td>[(positive, 0.3333333333333333)]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>[As, is, true, of, a, bunch, of, the, fall, cl...</td>\n",
       "      <td>[(positive, 0.3448275862068966)]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "      <td>I so wanted this skirt to work love the design...</td>\n",
       "      <td>[I, so, wanted, this, skirt, to, work, love, t...</td>\n",
       "      <td>[(positive, 0.25), (negative, 0.25), (joy, 0.2...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Love love this i was hesitant to buy this at f...</td>\n",
       "      <td>[Love, love, this, i, was, hesitant, to, buy, ...</td>\n",
       "      <td>[(positive, 0.19047619047619047), (joy, 0.1904...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>[I, absolutely, love, the, retro, look, of, th...</td>\n",
       "      <td>[(positive, 0.2222222222222222)]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating  \\\n",
       "0  Like other reviewers i was hesitant to spend t...       5   \n",
       "1  As is true of a bunch of the fall clothing pho...       5   \n",
       "2  I so wanted this skirt to work, love the desig...       1   \n",
       "3  Love love this! i was hesitant to buy this at ...       5   \n",
       "4  I absolutely love the retro look of this swims...       5   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0  Like other reviewers i was hesitant to spend t...   \n",
       "1  As is true of a bunch of the fall clothing pho...   \n",
       "2  I so wanted this skirt to work love the design...   \n",
       "3  Love love this i was hesitant to buy this at f...   \n",
       "4  I absolutely love the retro look of this swims...   \n",
       "\n",
       "                                    tokenized_review  \\\n",
       "0  [Like, other, reviewers, i, was, hesitant, to,...   \n",
       "1  [As, is, true, of, a, bunch, of, the, fall, cl...   \n",
       "2  [I, so, wanted, this, skirt, to, work, love, t...   \n",
       "3  [Love, love, this, i, was, hesitant, to, buy, ...   \n",
       "4  [I, absolutely, love, the, retro, look, of, th...   \n",
       "\n",
       "                                             emotion      core      prob  \n",
       "0                   [(positive, 0.3333333333333333)]  positive  0.333333  \n",
       "1                   [(positive, 0.3448275862068966)]  positive  0.344828  \n",
       "2  [(positive, 0.25), (negative, 0.25), (joy, 0.2...  positive  0.250000  \n",
       "3  [(positive, 0.19047619047619047), (joy, 0.1904...  positive  0.190476  \n",
       "4                   [(positive, 0.2222222222222222)]  positive  0.222222  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ed185",
   "metadata": {},
   "source": [
    "Now we begin fitting our model. We being by split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b4655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ratings['prob'], ratings['rating'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a559935",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296ff28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "X_train = X_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b171a65",
   "metadata": {},
   "source": [
    "We standarize both our training and testing datasets to have a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3aa210",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train.reshape(-1,1))\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler = StandardScaler().fit(X_test.reshape(-1,1))\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b308bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    print(np.std(X_train[:,i]))\n",
    "for i in range(X_test.shape[1]):\n",
    "    print(np.std(X_test[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e0cf8b",
   "metadata": {},
   "source": [
    "We use the $\\text{RandomizedSearchCV}$ function and the $\\text{RepeatedStratifedKFold}$ function in sklearn to conduct a randomized search on hyperparameters and then conduct k-fold cross validation with 5 folds. This is to ensure we find the best set of hyperparameters to optimize our logistic regression model, which is also from $\\text{sklearn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14a19cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5820 fits failed out of a total of 7500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "660 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1665 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1149, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 97, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1020 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "705 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "930 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/nicolepark/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.55949813        nan        nan        nan        nan\n",
      "        nan 0.55949813        nan 0.55949813 0.55949813        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan 0.55949813        nan 0.55949813\n",
      "        nan 0.55949813        nan        nan        nan 0.55949813\n",
      "        nan 0.55949813        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan 0.55949813        nan 0.55949813\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      " 0.55949813        nan 0.55949813        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      "        nan        nan        nan 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.55949813        nan 0.55949813        nan        nan\n",
      " 0.55949813        nan        nan 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      "        nan        nan 0.55949813        nan 0.55949813 0.55949813\n",
      "        nan 0.55949813        nan        nan        nan        nan\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan 0.55949813        nan 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan 0.55949813        nan 0.55949813\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan        nan 0.55949813\n",
      "        nan 0.55949813 0.55949813        nan        nan        nan\n",
      "        nan 0.55949813 0.55949813 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan 0.55949813 0.55949813\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.55949813        nan 0.55949813\n",
      "        nan        nan        nan        nan 0.55949813 0.55949813\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      " 0.55949813        nan        nan 0.55949813        nan        nan\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      " 0.55949813 0.55949813 0.55949813        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan        nan 0.55949813\n",
      "        nan 0.55949813        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55949813 0.55949813        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.55949813        nan        nan 0.55949813\n",
      "        nan 0.55949813        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.55949813\n",
      " 0.55949813        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.55949813        nan 0.55949813        nan\n",
      "        nan        nan        nan 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.55949813        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan 0.55949813        nan 0.55949813        nan\n",
      "        nan 0.55949813 0.55949813        nan        nan        nan\n",
      "        nan        nan        nan 0.55949813        nan 0.55949813\n",
      "        nan        nan 0.55949813        nan        nan 0.55949813\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.55949813        nan        nan        nan        nan\n",
      "        nan 0.55949813        nan        nan 0.55949813        nan\n",
      "        nan        nan 0.55949813        nan        nan        nan\n",
      "        nan        nan 0.55949813 0.55949813        nan 0.55949813\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.55949813        nan 0.55949813        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55949813        nan        nan        nan 0.55949813        nan\n",
      " 0.55949813        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.55949813        nan\n",
      " 0.55949813        nan 0.55949813        nan        nan 0.55949813\n",
      "        nan 0.55949813        nan 0.55949813 0.55949813        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "# Use k-fold cross validation with 5 folds\n",
    "model = LogisticRegression(multi_class = 'multinomial')\n",
    "cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3,random_state=1)\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5,100)\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring = 'accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X_train, np.squeeze(y_train))\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67dc42eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0018452045446539e-05, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d830cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test data set is 0.5579019073569482 or 55.79%.\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C = result.best_params_['C'], penalty = result.best_params_['penalty'], solver = result.best_params_['solver'], max_iter = 500).fit(X_train, np.squeeze(y_train))\n",
    "score = model.score(X_test, np.squeeze(y_test))\n",
    "print('The accuracy of the model on the test data set is ' + str(score) + ' or ' + str(round(score*100,2)) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f843a4",
   "metadata": {},
   "source": [
    "Our model accuracy is 55.79%, which is not awful. This means that the model is accurately predicting the rating based on the review at least half the time. However, we can try other models to see if they improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07ae44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test data set is 0.5579019073569482 or 55.79%.\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = clf.score(X_test, np.squeeze(y_test))\n",
    "print('The accuracy of the model on the test data set is ' + str(score) + ' or ' + str(round(score*100,2)) + '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cdddacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Amazon Dataset Ratings')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratings['rating']) # skewed right, lots of five-star reviews, little one-star reviews\n",
    "plt.ylabel('Value Counts')\n",
    "plt.xlabel('Star Rating (from 1-5)')\n",
    "plt.title('Histogram of Amazon Dataset Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ba6d8",
   "metadata": {},
   "source": [
    "Upon looking at the distribution of star ratings, this explains why support vector machine performs poorly. We have a highly unnbalanced dataset, which is a large weakness of support vector machines. With this type of model, because the soft margin is weak, the decision hyperplanes become skewed towards the minority class when the model is training.\n",
    "\n",
    "Some ways to mitigate this is to balance the dataset by resampling so that there is an even distribution of ratings or to use class weights that reflect the proportion of each rating in the training dataset.\n",
    "\n",
    "This was an implementation of sentiment analysis, logistic regression on a dataset to classify text reviews into star ratings, hyperparameter optimization, and some comparison of different classificaation models from a publicily available dataset at: https://www.kaggle.com/datasets/whenamancodes/amazon-reviews-on-women-dresses?resource=download."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
